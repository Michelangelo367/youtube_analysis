---
title: 'Features of Far-right Influences on YouTube'
author: "Hope Johnson <br>"
date: "April 2018"
output: github_document
---

```{r libraries, message=FALSE, warning=FALSE}
library(tidyverse)
library(jsonlite)
library(stringr)
library(lubridate)
library(magrittr)
library(skimr)
```

```{r echo = FALSE}
options(width = 120)
#skim_with(numeric = funs, append = FALSE)
skim_with(numeric = list(hist = NULL))
# just a late-night thought for later but HEY this github_document output shit is annoying so just knit to an html and keep the md for later.... because seriously i think an html will do the trick
```

# Opening

This work was created to support the Media Manipulation Initiative (MMI) at Data & Society. The goal of the the Media Manipulation Initiative is to examine how different groups use the participatory culture of the internet to turn the strengths of a free society into vulnerabilities, ultimately threatening expressive freedoms and civil rights. For this task, reserachers at the Media Manipulation Initiative are interested in how YouTube influences are attacking the mainstream media. One of the most active influencers is Alex Jones, and his media network InfoWars. By taking a deep dive into Alex Jones' YouTube videos, the research team will learn how discourse related to the mainstream media differs from other content uploaded by Alex Jones.

What follows is the data-generating, cleaning and analytical process for a slice of content uploaded to the Alex Jones Channel (between January 1st, 2015 and May 4th, 2018). The data for this task was scraped using Google's Youtube Data API. The code to extract such data lives in `get-dat.py`, available in the code folder. The extracting function in `get-dat.py` would be useful to extract future data from the YouTube API. Other developers are welcome to utilize this code as a way to make YouTube video data more accessible for their research.

*add outcomes*

# Munge data

I am targeting the title, description, tags, number of likes, number of dislikes, and number of views for each video uploaded to the Alex Jones YouTube channel during the specified three-year time period. The video statistics data arrives as a .json file, which for a single video appears like the chunk below.

```{r, eval = FALSE}
 {
        "etag": "\"DuHzAJ-eQIiCIp7p4ldoVcVAOeY/3xbKWLXhghfFL-E8ShUKH9FmQkI\"",
        "items": [
            {
                "etag": "\"DuHzAJ-eQIiCIp7p4ldoVcVAOeY/JEIv93BVt7HnVH5wreobXMimZJs\"",
                "id": "JEkS5w3NegA",
                "kind": "youtube#video",
                "snippet": {
                    "categoryId": "25",
                    "channelId": "UCvsye7V9psc-APX6wV1twLg",
                    "channelTitle": "The Alex Jones Channel",
                    "defaultAudioLanguage": "en",
                    "description": "Dr. Ed Group joins Alex Jones live in studio to expose how 5G cell phone radiation is poisoning the population by microwaving our cells/DNA to prevent people from reproducing the human species.",
                    "liveBroadcastContent": "none",
                    "publishedAt": "2018-05-03T21:55:03.000Z",
                    "tags": [
                        "Infowars",
                        "Alex Jones",
                        "Donald Trump",
                        "Politics",
                        "Prison Planet",
                        "1776",
                        "False Flag",
                        "911",
                        "Russia",
                        "Collusion",
                        "News",
                        "War",
                        "WW3"
                    ],
                    "title": "BREAKING: Government Admits 5G Is Killing You And Your Family"
                },
                "statistics": {
                    "commentCount": "320",
                    "dislikeCount": "38",
                    "favoriteCount": "0",
                    "likeCount": "783",
                    "viewCount": "20182"
                }
            }
        ],
        "kind": "youtube#videoListResponse",
        "pageInfo": {
            "resultsPerPage": 1,
            "totalResults": 1
        }
    }
```

JSON stands for JavaScript Object Notation, and this file format is commonly used to store data on the web. For data analysis and visualization, JSON is not ideal. As an initial step, I write a number of helper functions to convert a nested list item into a dataframe. I want to build up a [tidy](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html) dataframe, where each variable has its own column and each video has its own row.

If the code below means nothing to you, don't worry! I'm mostly keeping these helper functions here in order to remember what I did later on. The main takeaway is that data munging gets us from the nested, concave format shown above to a rectangular, tidy one for easy analysis.

```{r helper_function}
# For more on .json file flattening, see:
# https://stackoverflow.com/questions/35444968/read-json-file-into-a-data-frame-without-nested-lists

col_fixer <- function(x, vec2col = FALSE) {
  if (!is.list(x[[1]])) {
    if (isTRUE(vec2col)) {
      as.data.table(data.table::transpose(x))
    } else {
      vapply(x, toString, character(1L))
    }
  } else {
    temp <- rbindlist(x, use.names = TRUE, fill = TRUE, idcol = TRUE)
    temp[, .time := sequence(.N), by = .id]
    value_vars <- setdiff(names(temp), c(".id", ".time"))
    dcast(temp, .id ~ .time, value.var = value_vars)[, .id := NULL]
  }
}

Flattener <- function(indf, vec2col = FALSE) {
  require(data.table)
  require(jsonlite)
  indf <- flatten(indf)
  listcolumns <- sapply(indf, is.list)
  newcols <- do.call(cbind, lapply(indf[listcolumns], col_fixer, vec2col))
  indf[listcolumns] <- list(NULL)
  cbind(indf, newcols)
}

#' @return flattened video item with a column for each nested piece of information from json
make_tidy <- function(item){
  colNames <- c("categoryId", "channelId", "channelTitle", "defaultAudioLanguage", "description",
                "liveBroadcastContent", "localized", "tags", "publishedAt", "thumbnails", "title") # only keep columns I care about
  item <- data.frame(item)
  { if (length(colNames) != length(names(item$snippet))) {
      missingCols <- setdiff(union(names(item$snippet), colNames), intersect(names(item$snippet), colNames))
      item$snippet[, missingCols] <- ""   
      if ("tags" %in% missingCols) {item$snippet$tags <- list(0)}
      item$snippet <- item$snippet[colNames]  
      item$snippet[ ,order(names(item$snippet))]
      }  
  }
  Flattener(item) %>%
  as_data_frame()
}

#' @return clean, flat dataframe from .json file where each unique video is a row
clean_full_dat <- function(file){
  df <- fromJSON(file) %>%
  pull(items) %>%
  lapply(make_tidy) %>%
  bind_rows() %>%
  select(-(contains("thumbnails"))) %>%
  rename_(.dots = setNames(names(.),
                           gsub("snippet.","", names(.)))) %>%
  rename_(.dots = setNames(names(.), gsub("statistics.","", names(.)))) %>%
  mutate_at(vars(contains("Count")), funs(as.numeric)) %>%
  mutate(publishedAt = ymd_hms(publishedAt),
         year = year(publishedAt)) %>%
    # the etag has something to do with the video being updated (possibly, edited)
    select(-etag) %>%
    # keep the video observation with the highest viewCount (likely the most up-to-date)
    arrange(id, desc(viewCount)) %>%
    group_by(id) %>%
    filter(row_number() == 1) %>%
    ungroup()
  return(df)
}
```

GitHub doesn't like it when users store data within a repository. If you would like the raw json and/or tidy data rather than running the code provided, please get in touch with me via email.

```{r convert_dat, warning=FALSE, error=FALSE, message=FALSE, eval=FALSE}
full_dat <- clean_full_dat("../data/vid_details.json")
#write_rds(full_dat, "data/video_metadata.rds") # .rds for type persistence
```

```{r, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE}
full_dat <- read_csv(file.path("C:", "Users", "hjohnson", "Root", "Internal", "youtube_results", "data", "video_metadata.csv"))
```

`full_dat` contains video titles, viewer statistics, and other details for all the videos uploaded to the Alex Jones channel between between January 1st, 2015 and May 4th, 2018. Each row in the dataset represents a single video, and we observe `r nrow(full_dat)` videos in total. Each video has `r length(full_dat)` variables of interest (i.e. features, covariates, or inputs) associated with it. 

## Filter to media manipulation-related videos

The reserach team is interested in gathering insights from (1) the full collection of videos, and (2) a subset of videos with tags identified as relevant to discourse against mainstream media.

To create a dataset with only the words identified by researchers as relevant, I perform a search of the following attributes of each video: tags, description, and title. If any of the relevant terms show up in any of those three items, I save the video to a secondary dataframe, `ms_dat`. Note that any escape characters attached to relevant_terms (e.g., "buzzfeed/n", indicating a new paragraph) will still be found in the search function.

```{r filter_data, warning = FALSE, error = FALSE}
relevant_terms <- c("Mainstream media",
              "MSM",
              "CNN",
              "Mtv",
              "buzzfeed",
              "Nytimes",
              "ny times",
              "New york times",
              "Wapo",
              "Washington post",
              "Msnbc",
              "Lamestream",
              "propaganda")
pattern <- paste0(relevant_terms, collapse = "|")

mainstream_filter <- function(data, feature) {
  select <- str_detect(data[[feature]], regex(paste0("(?i)", pattern)))
  data <- data[select, ]
  return(data)
}

subset_by_tags <- mainstream_filter(full_dat, "tags")
subset_by_description <- mainstream_filter(full_dat, "description")
subset_by_title <- mainstream_filter(full_dat, "title")
```

I stack three dataframes on top of each other. These three dataframes represent the results with keywords in (1) the video description, (2) the video tags, and (3) the video title. 

```{r make_ms_dat, eval=FALSE, warning=FALSE, error=FALSE}
ms_dat <- subset_by_description %>%
  bind_rows(subset_by_tags) %>%
  bind_rows(subset_by_title) %>%
  distinct()
#write.csv(ms_dat, "data/video_metadata_mainstream_media.csv")
```

```{r, echo=FALSE, warning = FALSE, error=FALSE, message = FALSE}
ms_dat <- read_csv(file.path("C:", "Users", "hjohnson", "Root", "Internal", "youtube_results", "data", "video_metadata_mainstream_media.csv"))
```

# Exploration and Analysis

I poke around with variables of interest from both the full dataset and the data filtered down to only those videos related to the mainstream media. Some characteristics may vary between the two datasets; I aim to draw out what they are.

## Summary statistics

Below are summary statistics for numeric variables of the full dataset.

```{r full_dat summary statistics, results='asis', echo = FALSE}
skim(full_dat, commentCount, dislikeCount, favoriteCount, likeCount, viewCount, year) %>%
  skimr::kable(caption = "Summary statistics for all videos", format = "markdown")
```

In contrast, the table below provides summary statistics for videos with **mainstream-media tags**.

```{r summarize, results='asis', echo = FALSE}
skim(ms_dat, commentCount, dislikeCount, favoriteCount, likeCount, viewCount, year) %>% skimr::kable(caption = "Summary statistics for mainstream-related video subset")
```

When I compare the two tables, I immediately notice a few things:

1. `favoriteCount` doesn't provide any information.
2. The average number of dislikes on the videos in our mainstream subset is higher than the average for all videos.  The average number of dislikes in the mainstream subset is 845, whereas the average number of dislikes for all videos is 639. That said, the standard deviation is also much greater for the mainstream subset than for the full dataset. This means that the number of likes are less tightly clustered around the mean for the videos in the mainstream subset relative to the full dataset.
3. The same is true for number of likes, despite the fact that the average number of views for the videos in the mainstream subset is lower than for the overall videos. The average number of likes for the videos in the mainstream subset is 4854, whereas the average number of likes for all videos is 4508.
4. The median date published for the full dataset is December 4th, 2017. The median date published for the mainstream subset is August 10th, 2017. This suggests that the temporal pattern of videos differs between the two datasets. I'll explore this point first in the section below. 

## Date Published

Although the publication date for the video data spans from the beginning of 2015 and mid-2018, the median video date is December 4th, 2017. This suggests that Alex Jones increased his rate of video publication over time. The plot below shows videos published over time, where each dot represents a single video uploaded.

```{r message=FALSE, warning=FALSE, error=FALSE, fig.align="center"}
break.vec<-c(seq(from=as.Date("2015-01-08"), to=as.Date("2018-05-03"), by = "3 month"))

ggplot(full_dat, aes(as.Date(publishedAt))) + 
 geom_dotplot(stackdir = "center", stackratio = .2, alpha = .3,
              method = "histodot", binwidth = 40) + 
 scale_x_date(date_labels = "%b %y",
              breaks = break.vec) +
 scale_y_continuous(breaks = NULL) + 
 labs(x = "",  y = "", title = "Videos published by Alex Jones",
      subtitle = "January 2015 - May 2018")
```

Are videos related to the mainstream media published closer to the end of the period that we are interested in? Do they surround the 2016 presidential election? 

```{r, fig.align="center"}
cat_full_dat <- full_dat %>%
  mutate(main_stream_desc = ifelse(is.na(description), FALSE, str_detect(description, regex(paste0("(?i)", pattern)))),
         main_stream_title = str_detect(title, regex(paste0("(?i)", pattern))),
         main_stream_tags = str_detect(tags, regex(paste0("(?i)", pattern)))) %>%
  mutate(main_stream = ifelse((main_stream_desc | main_stream_tags | main_stream_title), "Mainstream-related videos", "Non mainstream-related videos"),
         Likes = likeCount/viewCount,
         Dislikes = dislikeCount/viewCount,
         Comments = commentCount/viewCount)

ggplot(cat_full_dat, aes(as.Date(publishedAt), color = main_stream, fill = main_stream)) + 
 geom_dotplot(stackdir = "center", stackratio = .2, alpha = .1,
              method = "histodot", binwidth = 40) + 
 scale_x_date(date_labels = "%b %y",
              breaks = break.vec) +
 scale_y_continuous(breaks = NULL) + 
 labs(x = "",  y = "", title = "Mainstream media-related videos over time",
      subtitle = "January 2015 - May 2018") + 
  theme(legend.position="bottom",
        legend.title=element_blank())
```

From the plot above, we see that videos published about the mainstream media were concentrated between December 2016 and August 2017. 

## Video Tags

Each video is tagged with a number of words and/or phrases by the uploader to optimize a YouTube serach. There are 410 unique tags in these data, and the average video has 17 tags associated with it. The bar chart below shows the most widely used tags in the time period between 2015 and mid-2018. The top five most commonly used tags were "Info Wars", "Hillary Clinton", "Alternative Media", "Alex Jones", and "War". I only show tags with greater than 5 occurences in the videos. 

```{r make_all_tag_count_df, message=FALSE, warning=FALSE, error=FALSE}
sepTags <- as.list(strsplit(full_dat$tags, ",")) %>%
  map_dfr(~ as_tibble(.)) %>%
  mutate(valClean = trimws(value), # match same tags (except spaces added)
         valClean = ifelse(str_detect(valClean, fixed("Info", ignore_case = TRUE)), "Info Wars", valClean),
         valClean = ifelse(str_detect(valClean, fixed("Alex Jones", ignore_case = TRUE)), "Alex Jones", valClean),
         valClean = ifelse(str_detect(valClean, fixed("Trump", ignore_case = TRUE)), "Donald Trump", valClean),
         valClean = ifelse(str_detect(valClean, fixed("Donald", ignore_case = TRUE)), "Donald Trump", valClean),
         valClean = ifelse(str_detect(valClean, fixed("Hillary", ignore_case = TRUE)), "Hillary Clinton", valClean),
         valClean = ifelse(str_detect(valClean, fixed("truth", ignore_case = TRUE)), "Truth", valClean)) 

tagTally <- sepTags %>%
  count(valClean, sort = TRUE) %>%
  filter(n > 5)
```

```{r count_tags_all_vids_plot, fig.align="center"}
ggplot(tagTally, aes(reorder(valClean, -n), n)) +
  geom_bar(stat = "identity") + 
  labs(x = "Tag", y = "# of tag occurences", title = "Video Tag Statistics") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Are the popular tags for all Alex Jones videos the same ones used for mainstream-media related videos? By examing the most widely-used tags on the subset videos related to mainstream media, I discover distinctions between the two groups. 

```{r make_ms_tag_count_df, echo = FALSE, message=FALSE, warning=FALSE, error=FALSE}
sepTags <- as.list(strsplit(ms_dat$tags, ",")) %>%
   map_dfr(~ as_tibble(.)) %>%
   mutate(valClean = trimws(value), # match same tags (except spaces added)
         valClean = ifelse(str_detect(valClean, fixed("Info", ignore_case = TRUE)), "Info Wars", valClean),
         valClean = ifelse(str_detect(valClean, fixed("Alex Jones", ignore_case = TRUE)), "Alex Jones", valClean),
         valClean = ifelse(str_detect(valClean, fixed("Trump", ignore_case = TRUE)), "Donald Trump", valClean),
         valClean = ifelse(str_detect(valClean, fixed("Donald", ignore_case = TRUE)), "Donald Trump", valClean),
         valClean = ifelse(str_detect(valClean, fixed("Hillary", ignore_case = TRUE)), "Hillary Clinton", valClean),
         valClean = ifelse(str_detect(valClean, fixed("truth", ignore_case = TRUE)), "Truth", valClean)) 

tagTally_ms <- sepTags %>%
  count(valClean, sort = TRUE) %>%
  filter(n > 5)
```

```{r ms_tag_count_plot, echo = FALSE, fig.align="center"}
ggplot(tagTally_ms, aes(reorder(valClean, -n), n)) +
  geom_bar(stat = "identity") + 
  labs(x = "", y = "# of tag occurences", title = "Video Tag Statistics", subtitle = "Mainstream-media related videos") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

To understand better whether there are meaninful differences in tags used for videos related to mainstream media, for the rest of this section I differentiate between mutually exlusive groups: tags for videos related to mainstream media, and tags for videos unrelated to mainstream media. I subtract the tag counts of `ms_dat` from the `full_dat` group. 

```{r make_tag_compare_dfs}
merged_tags <- left_join(tagTally, tagTally_ms, by = "valClean") %>%
	rename(n.full = n.x, n.ms = n.y) %>%
	mutate(n.nonms = n.full - n.ms,
		sum.ms = sum(n.ms, na.rm = TRUE),
		sum.nonms = sum(n.nonms, na.rm = TRUE),
		`Mainstream media-related videos` = n.ms/sum.ms,            # this is a proportion
		`Non mainstream media-related videos` = n.nonms/sum.nonms,  # this is also a proportion        
		diff = abs(`Mainstream media-related videos` - `Non mainstream media-related videos`)) 
		
all_tag_comps <- merged_tags %>%
		select(valClean, `Mainstream media-related videos`, `Non mainstream media-related videos`) %>%
		gather(type, proportion, -valClean)
		
var_tag_comps <- merged_tags %>%
	filter(diff > 0.02) %>%
	select(valClean, `Mainstream media-related videos`, `Non mainstream media-related videos`) %>%
	gather(type, proportion, -valClean)
```
To compare the popularity of each tag in the two groups, I divide the tag count by the total number of tags used in each group. 

```{r all_tag_compare_fig, fig.align="center"}
ggplot(all_tag_comps, aes(valClean, proportion, color = type, fill = type)) +
  geom_bar(stat = "identity", position = "dodge") + 
  labs(x = "Tag", y = "% of tag uses", title = "Vieo Tag Comparison") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  scale_y_continuous(labels = scales::percent) + 
  theme(legend.position="bottom",
        legend.title=element_blank())
```

It is difficult to visually infer tags from the plot with a sizable difference in usage across the two video types. In the plot below, I highlight tags with an absolute difference of more than two percent between the two groups. The make this more concrete, let's consider the most extreme example from the data: the "Info Wars" tag. This tag constitutes 3.7% of the tags in the mainstream media-related videos, and constitutes 12.5% of the tags in the non mainstream-media related videos. There is a difference of almost nine percentage points for this tag. 

```{r zoom_tag_compare_fig, fig.align="center"}
ggplot(var_tag_comps, aes(reorder(valClean, -proportion), proportion, color = type, fill = type)) +
  geom_bar(stat = "identity", position = "dodge") + 
  labs(x = "Tag", y = "% of tag uses", title = "Zoomed-In Tag Comparison") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
  scale_y_continuous(labels = scales::percent) + 
  theme(legend.position="bottom",
        legend.title=element_blank())
```

By comparing the two classes of videos, the data reveals that the tags "Info Wars", "Alternative Media", "Alex Jones", "War", "Truth", and "News Wars" are more often associated with non mainstream media-related videos. Tags including "Elections", "Fake", "Hack", "Lies", "MSM", "NSA", "Snowden", and "Wikileaks" are more often assciated with mainstream media-related videos. 

### Proportion of likes/dislikes to views

The summary tables above warrant an exploratory comparison of viewer engagement. With the data available, we quantify viewer engagement with the proportion of likes/dislikes to views. A higher proportion of dis/likes to views suggests increased audience engagement and responsiveness. I first reshape the data to facilitate such a comparison, and then present results in a density plot.

```{r add_props, fig.align="center"}
toPlot <- cat_full_dat %>%
  select(main_stream, Likes, Dislikes, Comments) %>%
  gather(var, prop, Likes:Comments)

ggplot(toPlot) +
  geom_density(aes(x=prop, y=..scaled.., fill = main_stream), alpha = 0.5) +
  facet_wrap(~var) +
  labs(x = "Proportion of engagement type to views",
       y = "Scaled density",
       title = "Viewer engagement by video type") +
  theme(legend.position = "bottom", legend.direction = "horizontal") +
  scale_fill_discrete("")
```

The y-axis on this plot is a scaled density because the sample sizes are different for videos with mainstream-tags and those without. The x-axis shows the proportion of the engagement type (comments, dislikes, likes) to the number of views for each video. The shading indicates whether the video had a mainstream tag or not.

The pink tail to the right within the "Likes" cell suggests that viewer engagement is higher for videos with mainstream tags than those without. This illuminates a potential motivation of mainstream media-related content creation. Previous research suggests that malicious actors creating and spreading disinformation, propaganda, and/or fake news are usually motivated by one or more of the following categories: ideology, money, and/or status or attention [0-1]. The differential in likes and views suggests that videos related to mainstream media garner more attention than the average video from the Alex Jones channel.   

# Discussion

Add major takeaways here

In future work, I will implement an in-depth analysis of the `description` text for each video.

# Closing

```{r version_info}
version
```

# Sources

[0] Alice Marwick and Rebecca Lewis, "Media Manipulation and Disinformation Online" (Data & Society Research Institute, May 17, 2017), https://datasociety.net/pubs/oh/DataAndSociety_MediaManipulationAndDisinformationOnline.pdf.

[1] Robyn Caplan and danah boyd, "Mediation, Automation, Power" (Data & Society Research Institute, May 15, 2016), https://datasociety.net/pubs/ap/MediationAutomationPower_2016.pdf.
